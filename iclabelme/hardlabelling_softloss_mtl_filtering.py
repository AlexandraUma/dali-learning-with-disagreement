# -*- coding: utf-8 -*-
"""softmax_gold_eval_label_me_complete.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kcPr2kAGU923sih8S2u9Ztwbt5Dmf_ux
"""

import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

import os

from scipy.spatial import distance
from scipy.special import kl_div
from scipy.stats import entropy
from sklearn.metrics.pairwise import cosine_similarity
from tabulate import tabulate

from random import shuffle

a = np.array([[0.0, 0.5, 0.3, 0.8, 1]])
b = np.array([[0.5, 0.0, 0.3, 0.8, 1]])
c = np.array([[0.1, 0.4, 0.4, 0.7, 0.9]])
gold = np.array([[1.0, 1.0, 0.0, 0.0, 0.33]])

cosine_similarity(a, b), np.corrcoef(a, b)[0][1]

cosine_similarity(a, c), np.corrcoef(a, c)[0][1]

np.sum(np.abs(a-b)), np.sum(np.abs(a-c))

13/25

from google.colab import drive

drive.mount('/content/drive')

"""**Configuration Parameters**"""

NUM_RUNS = 30
DATA_PATH = 'drive/My Drive/Data/LabelMe/prepared/'
N_CLASSES = 8
BATCH_SIZE = 64
N_EPOCHS = 50

"""**Loading the data**"""

def load_data(filename):
    f = open(filename, 'rb')
    data = np.load(f)
    f.close()
    return data

print("\nLoading train data...")

# originally just the train images but I need some of it to be used for soft label testing
train_test_vgg16 = load_data(DATA_PATH+"data_train_vgg16.npy")
train_test_labels = load_data(DATA_PATH+"labels_train.npy")

# indices = list(range(len(train_test_vgg16)))
# shuffle(indices)
# np.save(DATA_PATH+'shuffled_indices', np.array(indices))
indices = np.load(DATA_PATH+'shuffled_indices.npy').tolist()
train_indices = indices[1118:]
test_indices = indices[:1118]

data_train_vgg16 = train_test_vgg16[train_indices]
data_test_vgg16 = train_test_vgg16[test_indices]
labels_train = train_test_labels[train_indices]
labels_test = train_test_labels[test_indices]

print(data_train_vgg16.shape)
print(labels_train.shape)

# labels obtained from majority voting
labels_train_mv = load_data(DATA_PATH+"labels_train_mv.npy")[train_indices]
print(labels_train_mv.shape)
# labels obtained from Dawid and Skene aggregation
labels_train_ds = load_data(DATA_PATH+"labels_train_DS.npy")[train_indices]
print(labels_train_ds.shape)

# data from Amazon Mechanical Turk
print("\nLoading AMT data...")
all_answers = load_data(DATA_PATH+"answers.npy")

train_answers = all_answers[train_indices]
test_answers = all_answers[test_indices]

print(train_answers.shape, test_answers.shape)
N_ANNOT = train_answers.shape[1]
print("\nN_CLASSES:", N_CLASSES)
print("N_ANNOT:", N_ANNOT)


# load test data and validation data
print("\nLoading test and validation data...")

# test images and labels 
print(data_test_vgg16.shape)
print(labels_test.shape)

# validation images and labels
data_val_vgg16 = load_data(DATA_PATH+"data_valid_vgg16.npy")
print(data_val_vgg16.shape)
labels_val = load_data(DATA_PATH+"labels_valid.npy")
print(labels_val.shape)

print('Loading the repeated/sheng labels for the training data')

repeated_vgg16 = []
repeated_labels = []
for idx in train_indices:
    for vote in all_answers[idx]:
        if vote != -1:
            repeated_vgg16.append(train_test_vgg16[idx])
            repeated_labels.append(vote)
repeated_labels = np.array(repeated_labels)
repeated_vgg16 = np.array(repeated_vgg16)
print(len(repeated_vgg16), repeated_labels[0:3], train_answers[0])

"""**Converting Data to One-Hot Encoding**"""

def one_hot(target, n_classes):
    targets = np.array([target]).reshape(-1)
    one_hot_targets = np.eye(n_classes)[targets]
    return one_hot_targets

print("\nConverting to one-hot encoding...")
labels_train_bin = one_hot(labels_train, N_CLASSES)
print(labels_train_bin.shape)
labels_train_mv_bin = one_hot(labels_train_mv, N_CLASSES)
print(labels_train_mv_bin.shape)
labels_repeated_bin = one_hot(repeated_labels, N_CLASSES)
print(labels_repeated_bin.shape)
labels_train_ds_bin = one_hot(labels_train_ds, N_CLASSES)
print(labels_train_ds_bin.shape)

labels_test_bin = one_hot(labels_test, N_CLASSES)
print(labels_test_bin.shape)
labels_val_bin = one_hot(labels_val, N_CLASSES)
print(labels_val_bin.shape)

"""**Getting the Soft Labels and the distributions**"""

from scipy.special import softmax

train_distrs = []
train_softs = []
train_entropys = []
norm = [1/N_CLASSES for i in range(N_CLASSES)]

for item in train_answers.tolist():
    distr = [item.count(i) for i in range(N_CLASSES)]
    train_distrs.append(distr)
    num_votes = sum(distr)
    soft = softmax(distr)
    train_softs.append(soft)
    ent = entropy(soft)/entropy(norm)
    train_entropys.append(ent)

test_distrs = []
test_softs = []
test_entropys = []

for item in test_answers.tolist():
    distr = [item.count(i) for i in range(N_CLASSES)]
    test_distrs.append(distr)
    num_votes = sum(distr)
    soft = softmax(distr)
    test_softs.append(soft)
    ent = entropy(soft)/entropy(norm)
    test_entropys.append(ent)

# if forgot to get this while running the experiments
test_distr_dictionary = {}
for exp in range(30):
    test_distr_dictionary[str(exp)] = test_distrs


name = 'distrs'

writepath = 'drive/My Drive/Colab Notebooks/Significance_Testing/lm_experiments/'

print('Training using ' + name)
import json

with open(writepath+'lm_' + name + '.jsonlines', 'w') as f:
    json.dump(test_distr_dictionary, f)

len(train_softs), len(test_softs)

"""**Evaluation Metrics**"""

def get_acc_f1(test_trues, test_preds):
    total = 0
    correct = 0

    matches = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0}
    gold = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0}
    system = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0}

    for p, g in zip(test_preds,test_trues):
        total+=1
        if p == g:
            correct+=1
            matches[p] += 1

        gold[g] += 1
        system[p] += 1
    
    
    recall = {}
    precision = {}
    f1 = {}
    for i in range(N_CLASSES):
        recall[i] = 1.0 * matches[i] / gold[i] if matches[i] != 0 else 0
        precision[i] = 1.0 * matches[i] / system[i] if matches[i] !=0 else 0
        f1[i] =  (2 * (precision[i] * recall[i])/(precision[i] + recall[i])) if (precision[i] + recall[i]) > 0 else 0

    support = np.array([gold[i] for i in range(N_CLASSES)])

    average_recall = np.average([recall[i] for i in range(N_CLASSES)], weights=support)
    average_recall = np.average([recall[i] for i in range(N_CLASSES)], weights=support)
    average_precision = np.average([precision[i] for i in range(N_CLASSES)], weights=support)
    average_f1 = np.average([f1[i] for i in range(N_CLASSES)], weights=support)
    
    acc = correct/total

    return acc, average_precision, average_recall, average_f1

import numpy as np

np.average([67,90,23], weights=[2,1,3])

def get_ct_f1(test_trues, test_preds, test_distrs, num_classes=N_CLASSES):
    tp = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0}
    fp = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0}
    fn = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0}

    gold = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0}
    
    
    for p, g, distr in zip(test_preds, test_trues, test_distrs):
        # srs score of the gold not the predicted. Todo: talk it over with Massimo
        unit_vector = np.array([1 if i==g else 0 for i in range(num_classes)]).reshape(1,num_classes)
        distr = np.array(distr).reshape(1, num_classes)
        srs_s = cosine_similarity(unit_vector, distr)[0][0]
            
        if p == g:
            tp[p] += srs_s # correct hit
        else:
            fp[p] += (1-srs_s)  # miss
            fn[g] += srs_s   # correct rejection
    
        gold[g] += 1

    recall = {}
    precision = {}
    f1 = {}
    for i in range(num_classes):
        precision[i] = 1.0 * tp[i] / (tp[i] + fp[i]) if (fp[i] + tp[i]) != 0 else 0
        recall[i] = 1.0 * tp[i] / (tp[i] + fn[i]) if (fn[i] + tp[i]) !=0 else 0
        f1[i] =  (2 * (precision[i] * recall[i])/(precision[i] + recall[i])) if (precision[i] + recall[i]) > 0 else 0
        
    support = np.array([gold[i] for i in range(num_classes)])

    average_recall = np.average([recall[i] for i in range(num_classes)], weights=support)
    average_precision = np.average([precision[i] for i in range(num_classes)], weights=support)
    average_f1 = np.average([f1[i] for i in range(num_classes)], weights=support)

        
    return average_precision, average_recall, average_f1

def get_jsd_kl_div(soft_probs, predicted_probs):
    num_items = len(predicted_probs)
    all_jsd = [distance.jensenshannon(soft_probs[i], predicted_probs[i]) for i in range(num_items)]
    all_kl = [kl_div(soft_probs[i], predicted_probs[i]) for i in range(num_items)]
    return np.sum(all_jsd)/num_items, np.sum(all_kl)/num_items

def cross_entropy(predictions, targets, epsilon=1e-12):
    """
    Computes cross entropy between targets (encoded as one-hot vectors)
    and predictions.
    Input: predictions (N, k) ndarray
           targets (N, k) ndarray
    Returns: scalar
    """
    predictions = np.clip(predictions, epsilon, 1. - epsilon)
    N = predictions.shape[0]
    ce = -np.sum(targets*np.log(predictions))/N
    return ce

"""**Defining the Deep Learning Model**

Here we shall use features representation produced by the VGG16 network as the input. Our base model is then simply composed by one densely-connected layer with 128 hidden units and an output dense layer. We use 50% dropout between the two dense layers.
"""

class LabelMe_Classifier(nn.Module):
    def __init__(self, model_type='stl', smythe=None):
        super().__init__()
        
        self.hidden_layer = nn.Sequential(nn.Linear(8192, 128), 
                                          nn.LeakyReLU(),
                                          nn.Dropout(0.2))
        self.output_layer = nn.Sequential(nn.Linear(128, N_CLASSES))
        if model_type == 'mtl':
            self.second_output_layer = nn.Sequential(nn.Linear(128, N_CLASSES))
        
        self.model_type = model_type
        self.smythe = smythe


    def forward(self, data_input, one_hot_labels, soft_labels, eval=False):
        data_input = torch.flatten(data_input, 1)
        h = self.hidden_layer(data_input)
        output = self.output_layer(h)
        softmax_output = torch.softmax(output, 1) + 1e-45
        if not eval:
            soft_labels += + 1e-45 # necessary for KL but also used so the other methods are not disadvantaged
        if self.model_type != 'mtl':
            if eval: # because there is no soft val data, you don't want to get into this
                return _, softmax_output
            if self.model_type == 'stl' and not self.smythe:
                cross_entropy = torch.mul(one_hot_labels, softmax_output.log())
                loss = -torch.sum(cross_entropy)
            elif self.smythe == 'ce':
                cross_entropy = torch.mul(soft_labels, softmax_output.log())
                loss = -torch.sum(cross_entropy)
            elif self.smythe == 'kl':
                loss = torch.sum(torch.mul(soft_labels, (torch.div(soft_labels, softmax_output).log()))) 
            elif self.smythe == 'mse':
                loss = torch.nn.MSELoss(reduction='sum')(soft_labels, softmax_output)
            return loss, softmax_output
        else:
            output2 = self.second_output_layer(h)
            softmax_output2 = torch.softmax(output2, 1)
            if eval:
                return _,_,softmax_output, softmax_output2
            cross_entropy = torch.mul(one_hot_labels, softmax_output.log())
            hard_loss = -torch.sum(cross_entropy)
            soft_labels = soft_labels +  1e-45
            soft_loss = torch.sum(torch.mul(softmax_output2, (torch.div(softmax_output2, soft_labels).log()))) 
            # soft_loss = torch.sum(torch.mul(soft_labels, (torch.div(soft_labels, softmax_output2).log()))) 
            return hard_loss, soft_loss, softmax_output, softmax_output2

import json

writepath = 'drive/My Drive/Colab Notebooks/Significance_Testing/labelme_experiments/'

"""**Training using the Gold Labels**"""

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

# gold_dictionary = {}
true_labels_hard = {}
true_labels_soft = {}


for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(data_train_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(labels_train_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('stl').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        loss, _ = model(train_x, train_y1, train_y2)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        model.eval()
        _, val_pred = model(val_x, val_y1, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('stl').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _, test_pred = model(test_x, test_y1, test_y2)
    test_pred = test_pred.detach().cpu().numpy()
    # gold_dictionary[exp] = test_pred.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()
    true_labels_hard[exp] = test_labels
    true_labels_soft[exp] = test_y2.detach().cpu().numpy().tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    
    ce_res = cross_entropy(test_pred, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_trueLabels.jsonlines', 'w') as f:
    json.dump(true_labels_hard, f)

with open(writepath+'lm_trueSofts.jsonlines', 'w') as f:
    json.dump(true_labels_soft, f)

len(true_labels_hard[1])

true_labels_soft[1]

with open(writepath+'lm_gold.jsonlines', 'w') as f:
    json.dump(gold_dictionary, f)


print('Gold Accuracy stats after 30 epochs: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nGold PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nGold Crowdtruth PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nGold JSD stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nGold KL stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nGold entropy similarity stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nGold entropy correlation stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nGold cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

"""**Training Using Majority Voting**"""

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

mv_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(data_train_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(labels_train_mv_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('stl').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        loss, _ = model(train_x, train_y1, train_y2)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        model.eval()
        _, val_pred = model(val_x, val_y1, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('stl').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _, test_pred = model(test_x, test_y1, train_y2)
    test_pred = test_pred.detach().cpu().numpy()
    mv_dictionary[exp] = test_pred.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    
    ce_res = cross_entropy(test_pred, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_mv.jsonlines', 'w') as f:
    json.dump(mv_dictionary, f)


print('MV Accuracy stats after 30 experiments: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nMV PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nMV Crowdtruth PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nMV JSD stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nMV KL stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nMV entropy similarity stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nMV entropy correlation stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nMV cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

"""**Training Using the Jamison and Gureych approximation of Sheng et al, trying various loss functions**"""

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

mse_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(data_train_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(labels_train_mv_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('smythe', 'mse').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        loss, _ = model(train_x, None, train_y2)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        model.eval()
        _, val_pred = model(val_x, None, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('smythe', 'mse').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _, test_pred = model(test_x, None, test_y2)
    test_pred = test_pred.detach().cpu().numpy()
    mse_dictionary[exp] = test_pred.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    
    ce_res = cross_entropy(test_pred, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_mse.jsonlines', 'w') as f:
    json.dump(mse_dictionary, f)


print('Smythe_MSE Accuracy stats after 30 experiments: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nSmythe_MSE PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nSmythe_MSE Crowdtruth PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nSmythe_MSE JSD stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nSmythe_MSE KL stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nSmythe_MSE entropy similarity stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nSmythe_MSE entropy correlation stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nSmythe_MSE cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

ce_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(data_train_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(labels_train_mv_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('smythe', 'ce').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        loss, _ = model(train_x, None, train_y2)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        model.eval()
        _, val_pred = model(val_x, None, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('smythe', 'ce').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _, test_pred = model(test_x, None, test_y2)
    test_pred = test_pred.detach().cpu().numpy()
    ce_dictionary[exp] = test_pred.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    
    ce_res = cross_entropy(test_pred, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_ce.jsonlines', 'w') as f:
    json.dump(ce_dictionary, f)


print('Smythe_CE Accuracy stats after 30 experiments: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nSmythe_CE PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nSmythe_CE Crowdtruth PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nSmythe_CE JSD stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nSmythe_CE KL stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nSmythe_CE entropy similarity stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nSmythe_CE entropy correlation stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nSmythe_CE cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

kl_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(data_train_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(labels_train_mv_bin).float().cuda(), torch.tensor(train_softs).double().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('smythe', 'kl').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        loss, _ = model(train_x, None, train_y2)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        model.eval()
        _, val_pred = model(val_x, None, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('smythe', 'kl').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _, test_pred = model(test_x, None, test_y2)
    test_pred = test_pred.detach().cpu().numpy()
    kl_dictionary[exp] = test_pred.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    
    ce_res = cross_entropy(test_pred, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_kl.jsonlines', 'w') as f:
    json.dump(kl_dictionary, f)


print('Smythe_KL Accuracy stats after 30 experiments: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nSmythe_KL PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nSmythe_KL Crowdtruth PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nSmythe_KL JSD stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nSmythe_KL KL stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nSmythe_KL entropy similarity stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nSmythe_KL entropy correlation stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nSmythe_KL cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

"""**Training using the Fornaciari et al multi-task learning approach**"""

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

mtl_hard_dictionary = {}
mtl_soft_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(data_train_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(labels_train_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('mtl').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        hard_loss, soft_loss, _,_ = model(train_x, train_y1, train_y2)
        # each backward step accumulates the gradients which are later backpropagated by step function
        optimizer.zero_grad()
        soft_loss.backward(retain_graph=True)
        hard_loss.backward()
        optimizer.step()

        model.eval()
        _,_, val_pred,_ = model(val_x, None, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('mtl').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _,_, test_pred_h, test_pred_s = model(test_x, test_y1, test_y2)
    test_pred = test_pred_h.detach().cpu().numpy()
    mtl_hard_dictionary[exp] = test_pred.tolist()
    test_pred_soft = test_pred_s.detach().cpu().numpy()
    mtl_soft_dictionary[exp] = test_pred_soft.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred_soft)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred_soft]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    
    ce_res = cross_entropy(test_pred_soft, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_mtlHard.jsonlines', 'w') as f:
    json.dump(mtl_hard_dictionary, f)

with open(writepath+'lm_mtlSoft.jsonlines', 'w') as f:
    json.dump(mtl_soft_dictionary, f)


print('MTL Accuracy stats after 30 experiments: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nMTL PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nMTL Crowdtruth PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nMTL JSD stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nMTL KL stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nMTL entropy similarity stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nMTL entropy correlation stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nMTL cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

"""**Training using the Fornaciari et al multi-task learning approach MV**"""

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

mvmtl_hard_dictionary = {}
mvmtl_soft_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(data_train_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(labels_train_mv_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('mtl').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        hard_loss, soft_loss, _,_ = model(train_x, train_y1, train_y2)
        # each backward step accumulates the gradients which are later backpropagated by step function
        optimizer.zero_grad()
        soft_loss.backward(retain_graph=True)
        hard_loss.backward()
        optimizer.step()

        model.eval()
        _,_, val_pred,_ = model(val_x, None, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('mtl').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _,_, test_pred_h, test_pred_s = model(test_x, test_y1, test_y2)
    test_pred = test_pred_h.detach().cpu().numpy()
    mvmtl_hard_dictionary[exp] = test_pred.tolist()
    test_pred_soft = test_pred_s.detach().cpu().numpy()
    mvmtl_soft_dictionary[exp] = test_pred_soft.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred_soft)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred_soft]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]
    ce_res = cross_entropy(test_pred_soft, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_mvMtlHard.jsonlines', 'w') as f:
    json.dump(mvmtl_hard_dictionary, f)

with open(writepath+'lm_mvMtlSoft.jsonlines', 'w') as f:
    json.dump(mvmtl_soft_dictionary, f)


print('MTL Accuracy stats after 30 experiments: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nMTL PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nMTL Crowdtruth PRF stats after 30 experiments:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nMTL JSD stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nMTL KL stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nMTL entropy similarity stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nMTL entropy correlation stats after 30 experiments: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nMTL cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

"""**Trainining Using Sheng et al 2008**"""

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []


val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

sheng_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(repeated_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(labels_repeated_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('stl').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        loss, _ = model(train_x, train_y1, train_y2)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        model.eval()
        _, val_pred = model(val_x, val_y1, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  
        
    print(best_val_f)
    model = LabelMe_Classifier('stl').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _, test_pred = model(test_x, test_y1, test_y2)
    test_pred = test_pred.detach().cpu().numpy()
    sheng_dictionary[exp] = test_pred.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    ce_res = cross_entropy(test_pred, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_sheng.jsonlines', 'w') as f:
    json.dump(sheng_dictionary, f)


print('Sheng Accuracy stats after 30 epochs: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nSheng PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nSheng Crowdtruth PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nSheng JSD stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nSheng KL stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nSheng entropy similarity stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nSheng entropy correlation stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nSheng cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

"""**Training Using Labels Aggregated Using Dawid and Skene**"""

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

ds_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(data_train_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(labels_train_ds_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('stl').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        loss, _ = model(train_x, train_y1, train_y2)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        model.eval()
        _, val_pred = model(val_x, val_y1, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('stl').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _, test_pred = model(test_x, test_y1, test_y2)
    test_pred = test_pred.detach().cpu().numpy()
    ds_dictionary[exp] = test_pred.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    ce_res = cross_entropy(test_pred, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_ds.jsonlines', 'w') as f:
    json.dump(ds_dictionary, f)

print('DS Accuracy stats after 30 epochs: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nDS PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nDS Crowdtruth PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nDS JSD stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nDS KL stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nDS entropy similarity stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nDS entropy correlation stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nDS cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

"""**PART TWO: FILTERING THE LABELS**"""

def observed_agreement(annotations):
    """Aggrement is computed using Observed Agreement instead of
    Kappa i.e. (Ao-Ae)/(1-Ae) as expected agreement is not computed
    on a per item basis. TODO confirm with Massimo.
    """
    c = len (annotations)
    niks = [annotations.count(i) for i in set(annotations)]
    # getting the summ product
    numerator = sum([i*(i-1) for i in niks])
    if c == 1:
        return 1.0  # if only one annotator annotated it, it is a perfect agreement
    return numerator/(c*(c-1))

valid_annotations = [[i for i in ans if i != -1] for ans in train_answers]

avg_oa = np.average([observed_agreement(a) for a in valid_annotations])
print('Average observed agreement', avg_oa)

dis = []
for label in range(8):
    dis.append(np.average([observed_agreement(valid_annotations[idx]) for idx in range(len(valid_annotations)) if labels_train[idx] == label]))
print(dis)

import matplotlib.pyplot as plt

labels = 'coast, forest, highway, inside city, mountain, open country, street, tall building'.split(',')
plt.xticks(range(len(dis)), labels)
plt.xticks(rotation=45)
plt.xlabel('Gold label assigned to images')
plt.ylabel('Observed Agreement on images')
plt.bar(range(len(dis)), dis) 
plt.ylim(0, 1.0)
plt.show()

filtered_vgg16 = []
filtered_labels_gold = []
filtered_labels_mv = []
filtered_labels_ds = []
filtered_annotations = []
for idx in range(len(train_answers)):
    # filtering away any item with oa less than average for this dataset
    if observed_agreement(valid_annotations[idx]) > avg_oa:
        filtered_annotations.append(valid_annotations[idx])
        filtered_vgg16.append(data_train_vgg16[idx])
        filtered_labels_gold.append(labels_train[idx])
        filtered_labels_ds.append(labels_train_ds[idx])
        filtered_labels_mv.append(labels_train_mv[idx])

print('The number of annotations after filtering', len(filtered_vgg16))

prev_gt1 = [True for item in valid_annotations if len(set(item)) > 1]
gt_1 = [True for item in filtered_annotations if len(set(item)) > 1]
print('Previously %d items had more than one interpretation but there are now only %d items with more than one interpretation' %(len(prev_gt1), len(gt_1)))

a = [labels_train.tolist().count(i) for i in range(8)]
a

1080/1189

b = [filtered_labels_gold.count(i) for i in range(8)]
b

np.array(b)/np.array(a)

c = np.array(a) - np.array(b)
c

(612 + 602 + 565) / np.sum(c)

"""**Training Using Filtered Gold Labels**"""

filtered_vgg16 = np.array(filtered_vgg16)
filtered_labels_gold = np.array(filtered_labels_gold)
filtered_labels_mv = np.array(filtered_labels_mv)
filtered_labels_ds = np.array(filtered_labels_ds)

filtered_labels_gold_bin = one_hot(filtered_labels_gold, N_CLASSES)
print(filtered_labels_gold_bin.shape)
filtered_labels_ds_bin = one_hot(filtered_labels_ds, N_CLASSES)
print(filtered_labels_ds_bin.shape)
filtered_labels_mv_bin = one_hot(filtered_labels_mv, N_CLASSES)
print(filtered_labels_mv_bin.shape)

"""**Filtered Gold**"""

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

filtered_gold_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(filtered_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(filtered_labels_gold_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('stl').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        loss, _ = model(train_x, train_y1, train_y2)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        model.eval()
        _, val_pred = model(val_x, val_y1, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('stl').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _, test_pred = model(test_x, test_y1, test_y2)
    test_pred = test_pred.detach().cpu().numpy()
    filtered_gold_dictionary[exp] = test_pred.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    ce_res = cross_entropy(test_pred, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_filteredGold.jsonlines', 'w') as f:
    json.dump(filtered_gold_dictionary, f)


print('Filtered Gold Accuracy stats after 30 epochs: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nFiltered Gold PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nFiltered Gold Crowdtruth PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nFiltered Gold JSD stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nFiltered Gold KL stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nFiltered Gold entropy similarity stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nFiltered Gold entropy correlation stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nFiltered Gold cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

"""**Filtered MV**"""

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

filteredMV_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(filtered_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(filtered_labels_mv_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('stl').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        loss, _ = model(train_x, train_y1, train_y2)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        model.eval()
        _, val_pred = model(val_x, val_y1, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('stl').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _, test_pred = model(test_x, test_y1, test_y2)
    test_pred = test_pred.detach().cpu().numpy()
    filteredMV_dictionary[exp] = test_pred.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    ce_res = cross_entropy(test_pred, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_filteredMV.jsonlines', 'w') as f:
    json.dump(filteredMV_dictionary, f)

print('Filtered MV Accuracy stats after 30 epochs: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nFiltered MV PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nFiltered MV Crowdtruth PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nFiltered MV JSD stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nFiltered MV KL stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nFiltered MV entropy similarity stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nFiltered MV entropy correlation stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nFiltered MV cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

val_labels = labels_val.tolist()
test_labels = labels_test.tolist()
NUM_TEST = len(test_labels)

filteredDS_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d ###########'%exp)

    train_x, test_x, val_x = torch.tensor(filtered_vgg16).float().cuda(), torch.tensor(data_test_vgg16).float().cuda(), torch.tensor(data_val_vgg16).float().cuda()
    train_y1, train_y2 = torch.tensor(filtered_labels_ds_bin).float().cuda(), torch.tensor(train_softs).float().cuda()
    test_y1, test_y2 = torch.tensor(labels_test_bin).float().cuda(), torch.tensor(test_softs).float().cuda()
    val_y1 = torch.tensor(labels_val_bin).float().cuda()

    # load embeddings for that dataset
    model = LabelMe_Classifier('stl').cuda()
    optimizer = torch.optim.Adam(model.parameters())

    best_val_f = 0.0

    for epoch in range(1, N_EPOCHS+1):

        model.train()
        loss, _ = model(train_x, train_y1, train_y2)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        model.eval()
        _, val_pred = model(val_x, val_y1, None, True)
        val_acc, val_p, val_r, val_f = get_acc_f1(val_labels, torch.argmax(val_pred, 1).detach().cpu().numpy().tolist())
        if val_f > best_val_f:
            best_val_f = val_f
            torch.save(model.state_dict(), DATA_PATH+'best_model.pt')  

    model = LabelMe_Classifier('stl').cuda()
    model.load_state_dict(torch.load(DATA_PATH+'best_model.pt'))
    model.eval()
    _, test_pred = model(test_x, test_y1, test_y2)
    test_pred = test_pred.detach().cpu().numpy()
    filteredDS_dictionary[exp] = test_pred.tolist()
    predicted_test_labels = np.argmax(test_pred, 1).tolist()

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, predicted_test_labels)
    cp, cr, cf = get_ct_f1(test_labels, predicted_test_labels, test_distrs)

    jsd, kl = get_jsd_kl_div(test_softs, test_pred)

    preds_ents = [entropy(p)/entropy(norm) for p in test_pred]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    ce_res = cross_entropy(test_pred, test_softs)
    
    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)
    
    print(test_acc, test_f, cf, jsd, kl, ent, ce_res)
    print('#'*50)

with open(writepath+'lm_filteredDS.jsonlines', 'w') as f:
    json.dump(filteredDS_dictionary, f)

print('Filtered DS Accuracy stats after 30 epochs: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nFiltered DS PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nFiltered DS Crowdtruth PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nFiltered DS JSD stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nFiltered DS KL stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nFiltered DS entropy similarity stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nFiltered DS entropy correlation stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nFiltered DS cross entropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))

"""**Deep Learning From Crowds (DLFC) **"""


# -*- coding: utf-8 -*-
"""pos_complete.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qwMVBr_Ebsnayi1JByQSCkWoQ78ekjTU
"""
import torch
import time
import numpy as np
import torch.utils.data as data_utils
import pickle

from scipy.spatial import distance
from scipy.special import kl_div
from scipy.stats import entropy
from sklearn.metrics.pairwise import cosine_similarity
from tabulate import tabulate


device = 'cuda' if torch.cuda.is_available() else 'cpu'

def readbin(f_in):
    inp = open(f_in, "rb")
    out = pickle.load(inp)
    inp.close()
    return out

DATA_PATH = 'pos_data'

word_emb_matrix = DATA_PATH + '/word/dh_emb_matrix.bin'
word_pad_matrix = DATA_PATH + '/word/dh_pad_csr.bin'
word_id_in_sent  = DATA_PATH + '/word/dh_i_word_in_sent.bin'

char_emb_matrix = DATA_PATH + '/char/dh_emb_matrix.bin'
char_pad_matrix = DATA_PATH + '/char/dh_pad_csr.bin'

hot_path = DATA_PATH + '/labels/dh_hot_csr.bin'
soft_devtrn_path = DATA_PATH + '/raw_soft_labels/soft_devtrn.bin'
soft_tst_path = DATA_PATH + '/raw_soft_labels/soft_tst.bin'

softtstsize = 7877
tstsize = 3064
devsize = 2439

lstm_size = 128
attn_size = 512

num_epochs = 20

batsize = 1000
sizeout_rate = 0.8

word_emb_size = 300
char_emb_size = 64

num_users = 177
train_users = DATA_PATH + '/train_anno_users.npy'
train_status = DATA_PATH + '/train_anno_status.npy'

word_emb = readbin(word_emb_matrix)
word_iis = readbin(word_id_in_sent)
word_pad = readbin(word_pad_matrix)
char_emb = readbin(char_emb_matrix)
char_pad = readbin(char_pad_matrix)
soft_d_t = readbin(soft_devtrn_path)
soft_tst = readbin(soft_tst_path)

hot  = readbin(hot_path)
hotsize = hot.shape[1]
word_padsize = word_pad.shape[1]
char_padsize = char_pad.shape[1]

word_embedding_lookup = torch.from_numpy(word_emb).float().to(device)
char_embedding_lookup = torch.from_numpy(char_emb).float().to(device)

softst_tst  = softtstsize + tstsize
softst_tst_dev = softtstsize + tstsize + devsize

word_iis_tst  = word_iis[softtstsize:softst_tst] # da lowlands.test.tsv
word_iis_dev  = word_iis[softst_tst:softst_tst_dev] # da gimpel_crowdsourced
word_iis_trn  = word_iis[softst_tst_dev:] # da gimpel_crowdsourced

word_pad_tst  = word_pad[softtstsize:softst_tst].toarray() # da lowlands.test.tsv
word_pad_dev  = word_pad[softst_tst:softst_tst_dev].toarray() # da gimpel_crowdsourced
word_pad_trn  = word_pad[softst_tst_dev:].toarray() # da gimpel_crowdsourced

char_pad_tst  = char_pad[softtstsize:softst_tst].toarray() # da lowlands.test.tsv
char_pad_dev  = char_pad[softst_tst:softst_tst_dev].toarray() # da gimpel_crowdsourced
char_pad_trn  = char_pad[softst_tst_dev:].toarray() # da gimpel_crowdsourced

hot_tst = hot[:tstsize].toarray() # da lowlands.test.tsv
hot_dev = hot[tstsize:tstsize+devsize].toarray() # da gimpel_crowdsourced
hot_trn = hot[tstsize+devsize:].toarray() # da gimpel_crowdsourced

soft_test = soft_tst.values
soft_dev = soft_d_t[:devsize].values # da gimpel_crowdsourced
soft_train = soft_d_t[devsize:].values # da gimpel_crowdsourced

dlfc_trn_users = np.load(train_users)
dlfc_trn_status = np.load(train_status)

def lookup_embeddings(embedding_lookup, index_matrix):
    flattened_indices = torch.flatten(index_matrix)
    selected = torch.index_select(embedding_lookup, 0, flattened_indices)
    return selected.reshape(index_matrix.shape[0], index_matrix.shape[1], embedding_lookup.shape[-1])


def to_numpy(torch_tensor):
    return torch_tensor.cpu().clone().detach().numpy()

def to_cuda(x):
    """ GPU-enable a tensor """
    if torch.cuda.is_available():
        x = x.cuda()
    return x


def log2(x):
    numerator = torch.log(x)
    denom = to_cuda(torch.log(torch.tensor([2]).float()))
    out = numerator / denom
    out = torch.where(torch.isnan(out), torch.zeros_like(out), out)
    return out

def create_dataset(word_pad_trn_bat, word_iis_trn_bat, char_pad_trn_bat, y_hot_trn_bat, y_soft_trn_bat):
    word_pad_trn_bat, word_iis_trn_bat = torch.from_numpy(word_pad_trn_bat).long().to(device), torch.from_numpy(word_iis_trn_bat).long().to(device)
    char_pad_trn_bat, y_hot_trn_bat = torch.from_numpy(char_pad_trn_bat).long().to(device), torch.from_numpy(y_hot_trn_bat).float().to(device)
    y_soft_trn_bat = torch.from_numpy(y_soft_trn_bat).float().to(device)
    return word_pad_trn_bat, word_iis_trn_bat, char_pad_trn_bat, y_hot_trn_bat, y_soft_trn_bat

def create_train_dataset(word_pad_trn_bat, word_iis_trn_bat, char_pad_trn_bat, users_ids_bat, status_bat):
    word_pad_trn_bat, word_iis_trn_bat = torch.from_numpy(word_pad_trn_bat).long().to(device), torch.from_numpy(word_iis_trn_bat).long().to(device)
    char_pad_trn_bat, status_bat = torch.from_numpy(char_pad_trn_bat).long().to(device), torch.from_numpy(status_bat).long().to(device)
    users_ids_bat = torch.from_numpy(users_ids_bat).long().to(device)
    return word_pad_trn_bat, word_iis_trn_bat, char_pad_trn_bat, users_ids_bat, status_bat


def backprop_hot(optimizer, loss):
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    return

def backprop_both(optimizer, loss1, loss2):
    optimizer.zero_grad()
    loss2.backward(retain_graph=True)
    loss1.backward()
    optimizer.step()
    return

def get_acc_f1(test_trues, test_preds, num_classes=hotsize):
    total = 0
    correct = 0

    matches, gold, system = {}, {}, {}
    for i in range(num_classes):
        matches[i] = 0
        system[i] = 0
        gold[i] = 0

    for p, g in zip(test_preds,test_trues):
        total+=1
        if p == g:
            correct+=1
            matches[p] += 1

        gold[g] += 1
        system[p] += 1


    recall = {}
    precision = {}
    f1 = {}
    for i in range(num_classes):
        recall[i] = 1.0 * matches[i] / gold[i] if matches[i] != 0 else 0
        precision[i] = 1.0 * matches[i] / system[i] if matches[i] !=0 else 0
        f1[i] =  (2 * (precision[i] * recall[i])/(precision[i] + recall[i])) if (precision[i] + recall[i]) > 0 else 0

    support = np.array([gold[i] for i in range(num_classes)])

    average_recall = np.average([recall[i] for i in range(num_classes)], weights=support)
    average_recall = np.average([recall[i] for i in range(num_classes)], weights=support)
    average_precision = np.average([precision[i] for i in range(num_classes)], weights=support)
    average_f1 = np.average([f1[i] for i in range(num_classes)], weights=support)

    acc = correct/total

    return acc, average_precision, average_recall, average_f1



def get_ct_f1(test_trues, test_preds, test_distrs, num_classes=hotsize):

    tp, fp, fn, gold = {}, {}, {}, {}
    for i in range(num_classes):
        tp[i] = 0
        fp[i] = 0
        fn[i] = 0
        gold[i] = 0


    for p, g, distr in zip(test_preds, test_trues, test_distrs):
        # srs score of the gold not the predicted. Todo: talk it over with Massimo
        unit_vector = np.array([1 if i==g else 0 for i in range(num_classes)]).reshape(1,num_classes)
        distr = np.array(distr).reshape(1, num_classes)
        srs_s = cosine_similarity(unit_vector, distr)[0][0]
        if p == g:
            tp[p] += srs_s # correct hit
        else:
            fp[p] += (1-srs_s)  # miss
            fn[g] += srs_s   # correct rejection

        gold[g] += 1

    recall = {}
    precision = {}
    f1 = {}
    for i in range(num_classes):
        precision[i] = 1.0 * tp[i] / (tp[i] + fp[i]) if (fp[i] + tp[i]) != 0 else 0
        recall[i] = 1.0 * tp[i] / (tp[i] + fn[i]) if (fn[i] + tp[i]) !=0 else 0
        f1[i] =  (2 * (precision[i] * recall[i])/(precision[i] + recall[i])) if (precision[i] + recall[i]) > 0 else 0

    support = np.array([gold[i] for i in range(num_classes)])

    average_recall = np.average([recall[i] for i in range(num_classes)], weights=support)
    average_precision = np.average([precision[i] for i in range(num_classes)], weights=support)
    average_f1 = np.average([f1[i] for i in range(num_classes)], weights=support)


    return average_precision, average_recall, average_f1


def get_jsd_kl_div(soft_probs, predicted_probs):
    num_items = len(predicted_probs)
    all_jsd = [distance.jensenshannon(soft_probs[i], predicted_probs[i]) for i in range(num_items)]
    all_kl = [kl_div(soft_probs[i], predicted_probs[i]) for i in range(num_items)]
    return np.sum(all_jsd)/num_items, np.sum(all_kl)/num_items


def cross_entropy(predictions, targets, epsilon=1e-12):
    """
    Computes cross entropy between targets (encoded as one-hot vectors)
    and predictions.
    Input: predictions (N, k) ndarray
           targets (N, k) ndarray
    Returns: scalar
    """
    predictions = np.clip(predictions, epsilon, 1. - epsilon)
    N = predictions.shape[0]
    ce = -np.sum(targets*np.log(predictions))/N
    return ce


def get_predictions(model, eval_loader, mtl=False):
    hard_preds = []
    soft_preds = []
    model.eval()
    for wwordpad_bat, wwordiis_bat, ccharpad_bat, hhot_bat, ssoft_bat in eval_loader:
        if not mtl:
            one_hot_pred, _,_,_ = model(wwordpad_bat, wwordiis_bat, ccharpad_bat, None, None)
            one_hot_pred = one_hot_pred.detach().cpu().numpy()
            # the soft and hard predictions come from the same dense layer in the single task models.
            hard_preds.extend(np.argmax(one_hot_pred, 1))
            soft_preds.extend(one_hot_pred)
        else:
            one_hot_pred, soft_pred, _, _ = model(wwordpad_bat, wwordiis_bat, ccharpad_bat, hhot_bat, ssoft_bat)
            hard_preds.extend(one_hot_pred.argmax(-1).detach().cpu().numpy())
            soft_preds.extend(soft_pred.detach().cpu().numpy())
    return hard_preds, soft_preds


"""**Geting, Tensorizing and Batching the Data**"""
from scipy.special import softmax

NUM_TEST = len(hot_dev)
norm = [1/hotsize for i in range(hotsize)]
test_entropys = []
test_softs = []
test_distr = []
for distr in soft_dev:
    test_distr.append(distr)
    num_votes = np.sum(distr)
    soft = softmax(distr)
    #soft = [i/num_votes for i in distr]
    test_softs.append(soft)
    ent = entropy(soft)/entropy(norm)
    test_entropys.append(ent)

test_softs = np.array(test_softs)
test_entropys = np.array(test_entropys)
test_distr = np.array(test_distr)
test_softs.shape


# Alexandra, for these experiments, dev data for testing and test data for validation because dev data has actual soft labels.
word_pad_test_tens, word_iis_test_tens, char_pad_test_tens, hot_test_tens, soft_test_tens = create_dataset(word_pad_tst, word_iis_tst, char_pad_tst, hot_tst, soft_test)
dev = data_utils.TensorDataset(word_pad_test_tens, word_iis_test_tens, char_pad_test_tens, hot_test_tens, soft_test_tens[:len(hot_test_tens)]) # the soft test is just a placeholder and not actually useful or used
dev_loader = data_utils.DataLoader(dev, batch_size=batsize, shuffle=False)

word_pad_dev_tens, word_iis_dev_tens, char_pad_dev_tens, hot_dev_tens, soft_dev_tens = create_dataset(word_pad_dev, word_iis_dev, char_pad_dev, hot_dev, test_softs)
test = data_utils.TensorDataset(word_pad_dev_tens, word_iis_dev_tens, char_pad_dev_tens, hot_dev_tens, soft_dev_tens)
test_loader = data_utils.DataLoader(test, batch_size=batsize, shuffle=False)


"""**The Model**"""
class Word_Encoder(torch.nn.Module):
    def __init__(self, lstm_size, embedding_size):
        super().__init__()

        self.bilstm = torch.nn.LSTM(embedding_size, lstm_size, bidirectional=True, batch_first=True)
        self.dropout = torch.nn.Dropout(0.2)

    def forward(self, wword_pad, col_indices):
        embedded_words = lookup_embeddings(word_embedding_lookup, wword_pad)
        rnn_context, _ = self.bilstm(embedded_words)
        rnn_sequence = torch.stack([torch.index_select(seq, 0, i) for seq, i in zip(rnn_context, col_indices)], 0)
        rnn_sequence = self.dropout(rnn_sequence)
        return rnn_sequence, rnn_context


class Char_Encoder(torch.nn.Module):
    def __init__(self, lstm_size, embedding_size):
        super().__init__()

        self.bilstm = torch.nn.LSTM(embedding_size, lstm_size, bidirectional=True, batch_first=True)
        self.dropout = torch.nn.Dropout(0.2)

    def forward(self, cchar_pad):
        embedded_chars = lookup_embeddings(char_embedding_lookup, cchar_pad)
        rnn_sequence, _ = self.bilstm(embedded_chars)
        rnn_sequence = self.dropout(rnn_sequence[:,1])
        reshaped = torch.reshape(rnn_sequence, [-1, 1, rnn_sequence.shape[1]])
        return reshaped


class Attention(torch.nn.Module):
    def __init__(self, attn_emb_dim, attn_size):
        super().__init__()

        self.attn_nn = torch.nn.Sequential(
                    torch.nn.Linear(attn_emb_dim, attn_size),
                    torch.nn.Tanh()
        )

        self.u_omega = torch.nn.Parameter(torch.randn([attn_size]))

    def forward(self, attn_in, s):
        v = self.attn_nn(attn_in)
        vu = torch.matmul(v.squeeze(1), self.u_omega)
        alphas = torch.nn.functional.softmax(vu, 0)
        final = torch.sum(attn_in * alphas.unsqueeze(-1), 1)
        return final



class RNN_all(torch.nn.Module):
    def __init__(self):
        super().__init__()

        self.word_encoder = Word_Encoder(lstm_size, word_emb_size)
        self.char_encoder = Char_Encoder(lstm_size, char_emb_size)

        self.char_attention = Attention(lstm_size*2, attn_size)
        self.word_attention = Attention(lstm_size*2, attn_size)

        concat_size = lstm_size*4
        hidden1 = int(lstm_size*4*sizeout_rate)
        out_final = int(hidden1*sizeout_rate)
        self.fulcon = torch.nn.Sequential(
                    torch.nn.Linear(concat_size, hidden1),
                    torch.nn.Linear(hidden1, out_final))

        self.output_hot = torch.nn.Linear(out_final, hotsize)
        beta = torch.eye(hotsize)
        self.global_user_confusion = torch.nn.Parameter(beta.unsqueeze(0).repeat([num_users, 1, 1]))


    def forward(self, wword_pad, wword_iis, cchar_pad, anno_users, anno_status, test_mode=True):
        word_sequence, word_context = self.word_encoder(wword_pad, wword_iis)
        word_attn= self.word_attention(word_sequence, 'word')

        char_sequence = self.char_encoder(cchar_pad)
        char_attn = self.char_attention(char_sequence, 'char')

        concat_attn = torch.cat([word_attn, char_attn], 1)
        ful = self.fulcon(concat_attn)

        predictions = self.output_hot(ful)
        softmax_scores = torch.nn.functional.softmax(predictions, 1) + 1e-43
        if test_mode:
            return softmax_scores, None, 0.0, 0.0
        else:
            batch_size = anno_users.shape[0]
            max_anno_length = anno_users.shape[1]

            # flatten the user and class information
            flattened_anno_users = torch.flatten(anno_users) # [num_mentions, max_anno_length]
            flattened_anno_status = torch.flatten(anno_status)  # [num_mentions, max_anno_length]

            # use the mask to remove the useless padding-injected information from the user and the class tensors; one hot encode the latter
            valid_users = flattened_anno_users[flattened_anno_users>-1]         # [across_mention_annotations]
            valid_judgements = flattened_anno_status[flattened_anno_status>-1]     # [across_mention_annotations]
            judgements_one_hot = to_cuda(torch.eye(hotsize)[valid_judgements])     # [across_mention_annotations, 4]

            # extract the confusion matrices for the users who provided the annotations
            users_confusions = torch.index_select(self.global_user_confusion, 0, valid_users)  # [across_mention_annotations, 4, 4]

            # the scores produced by the neural network for each mention are used in the computation of every expected annotator response; so duplicate them appropriately
            duplicated_scores = predictions.unsqueeze(1)   # [num_mentions, 1, 4]
            duplicated_scores = duplicated_scores.repeat(1, max_anno_length, 1)    # [num_mentions, max_anno_length, 4]
            duplicated_scores = torch.reshape(duplicated_scores, (batch_size*max_anno_length, hotsize))  # [num_mentions * max_anno_length, 4]

            # corresponding mention scores for each annotation provided
            selected_scores = duplicated_scores[flattened_anno_status>-1]    # [across_mention_annotations, 4]
            # the expected annotator respone is a linear combination of the annotator confusion and the neural network prediction
            expected_user_responses = torch.matmul(users_confusions, selected_scores.unsqueeze(2)).squeeze(2)  # [across_mention_annotations, 4]

            expected_user_responses = torch.nn.functional.softmax(expected_user_responses, 1) + 1e-43
            cross_entropy = torch.mul(judgements_one_hot+1e-43, expected_user_responses.log())
            loss  = -torch.sum(cross_entropy)

            return softmax_scores, None, loss, 0.0

      

word_pad_trn_tens, word_iis_trn_tens, char_pad_trn_ten, anno_users_tens, anno_status_tens = create_train_dataset(word_pad_trn, word_iis_trn, char_pad_trn, dlfc_trn_users, dlfc_trn_status)
train = data_utils.TensorDataset(word_pad_trn_tens, word_iis_trn_tens, char_pad_trn_ten, anno_users_tens, anno_status_tens)
train_loader = data_utils.DataLoader(train, batch_size=batsize, shuffle=True)

print('-------------------------------------------------------- Training using dlfc-----------------------------------------')
print('Beginning the Training')
NUM_EXPERIMENTS = 30

accs = []
prfs = []
ct_prfs = []
jsds = []
kls = []
similarity_ents = []
ents_correlation = []
ce_results = []

dev_accs = []
dev_prfs = []

name = 'dlc'
dlc_dictionary = {}

for exp in range(NUM_EXPERIMENTS):
    print('\nExperiment %d #######################'%exp)
    best_val_f, best_val_acc = 0, 0
    best_val_r, best_val_p = 0, 0

    last_batch = 0

    model = RNN_all()
    model = to_cuda(model)
    optimizer = torch.optim.Adam(params=[p for p in model.parameters()],lr=0.001)

    for epoch in range(num_epochs):
        nepoch = epoch + 1
        model.train()

        for word_pad_trn_bat, word_iis_trn_bat, char_pad_trn_bat, y_anno_users, y_anno_status in train_loader:
            hard_predictions, _, hard_loss, _ = model(word_pad_trn_bat, word_iis_trn_bat, char_pad_trn_bat, y_anno_users, y_anno_status, False)
            backprop_hot(optimizer, hard_loss)

        # evaluate after each epoch using
        dev_hard_preds, dev_soft_preds = get_predictions(model, dev_loader, False)
        dev_acc, dev_p, dev_r, dev_f = get_acc_f1(dev_hard_preds, np.argmax(hot_tst, 1))
        if dev_f > best_val_f:
            best_val_f = dev_f
            best_val_acc = dev_acc
            best_val_r = dev_r
            best_val_p = dev_p
            torch.save(model.state_dict(), DATA_PATH+'/best_model.pt')
        print(f"[Epoch {nepoch}] accuracy on dev: {dev_acc * 100:0.5f}, f1 on dev: {dev_f * 100:0.5f}")

    dev_accs.append(best_val_acc)
    dev_prfs.append([best_val_p, best_val_r, best_val_f])

    # evaluating on the test data
    del model
    model = RNN_all().cuda()
    model.load_state_dict(torch.load(DATA_PATH+'/best_model.pt'))
    test_predictions, test_preds_soft = get_predictions(model, test_loader, False)
    test_labels = np.argmax(hot_dev,1)

    dirr = str(exp)
    dlc_dictionary[dirr] = [item.tolist() for item in test_preds_soft]

    test_acc, test_p, test_r, test_f = get_acc_f1(test_labels, test_predictions)
    cp, cr, cf = get_ct_f1(test_labels, test_predictions, soft_dev)

    jsd, kl = get_jsd_kl_div(test_softs, test_preds_soft)

    preds_ents = [entropy(p)/entropy(norm) for p in test_preds_soft]

    ent = cosine_similarity(np.array(test_entropys).reshape(1, NUM_TEST), np.array(preds_ents).reshape(1, NUM_TEST))[0][0]

    corr = np.corrcoef(test_entropys, preds_ents)[0][1]
    ce_res = cross_entropy(test_preds_soft, test_softs)

    accs.append(test_acc)
    prfs.append([test_p, test_r, test_f])
    ct_prfs.append([cp, cr, cf])
    jsds.append(jsd)
    kls.append(kl)
    similarity_ents.append(ent)
    ents_correlation.append(corr)
    ce_results.append(ce_res)

    print(test_acc, test_f, cf, jsd, kl, ent, corr, ce_res)
    print('#'*50)

import json
writepath = "predictions/"
with open(writepath+'gimpelpos_' + name + '.jsonlines', 'w') as f:
    json.dump(dlc_dictionary, f)


print('DLC Accuracy stats after 30 epochs: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(accs)*100, np.max(accs)*100, np.min(accs)*100, np.std(accs)*100))

print('\nDLC PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(prfs, 0).tolist()
maxs = ['maximums'] + np.max(prfs, 0).tolist()
mins = ['minimums'] + np.min(prfs, 0).tolist()
stds = ['stds'] + np.std(prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))

print('\nDLC Crowdtruth PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(ct_prfs, 0).tolist()
maxs = ['maximums'] + np.max(ct_prfs, 0).tolist()
mins = ['minimums'] + np.min(ct_prfs, 0).tolist()
stds = ['stds'] + np.std(ct_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['CT Precision', 'CT Recall', 'CT F1']))

print('\nDLC JSD stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(jsds), np.max(jsds), np.min(jsds), np.std(jsds)))

print('\nDLC KL stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(kls), np.max(kls), np.min(kls), np.std(kls)))

print('\nDLC entropy similarity stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(similarity_ents), np.max(similarity_ents), np.min(similarity_ents), np.std(similarity_ents)))

print('\nDLC entropy correlation stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ents_correlation), np.max(ents_correlation), np.min(ents_correlation), np.std(ents_correlation)))

print('\nDLC crossentropy stats after 30 epochs: Avg %0.4f, Max %0.4f, Min %0.4f, Std %0.4f' %(np.average(ce_results), np.max(ce_results), np.min(ce_results), np.std(ce_results)))


print('\n\nEVALUATING ON THE DEV SET I.E. THE FORNACIARA TEST SET')
print('DLC Accuracy stats after 30 epochs: Avg %0.2f, Max %0.2f, Min %0.2f, Std %0.2f' %(np.average(dev_accs)*100, np.max(dev_accs)*100, np.min(dev_accs)*100, np.std(dev_accs)*100))

print('\nDLC PRF stats after 30 epochs:... ')
avgs = ['averages'] + np.average(dev_prfs, 0).tolist()
maxs = ['maximums'] + np.max(dev_prfs, 0).tolist()
mins = ['minimums'] + np.min(dev_prfs, 0).tolist()
stds = ['stds'] + np.std(dev_prfs, 0).tolist()
print(tabulate([avgs, maxs, mins, stds], headers=['Precision', 'Recall', 'F1']))
print('-------------------------------------------------------------------------------------------------','\n\n')

